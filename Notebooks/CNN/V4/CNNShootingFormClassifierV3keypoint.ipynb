{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Trainied with keypoints"
      ],
      "metadata": {
        "id": "8qP52JJs2LC7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train"
      ],
      "metadata": {
        "id": "8IOu5oknR_Uk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler, random_split, Dataset\n",
        "from torchvision import transforms, datasets\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from collections import Counter\n",
        "from PIL import Image\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Define the CNN model\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = None  # Will be dynamically set in the forward pass\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # Store the activations and gradients\n",
        "        self.gradients = None\n",
        "        self.activations = None\n",
        "\n",
        "    def activations_hook(self, grad):\n",
        "        self.gradients = grad\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "\n",
        "        # Register hook to save gradients\n",
        "        if x.requires_grad:\n",
        "            h = x.register_hook(self.activations_hook)\n",
        "        self.activations = x  # Save activations\n",
        "\n",
        "        # Dynamically calculate the input size for fc1\n",
        "        if self.fc1 is None:\n",
        "            self.fc1 = nn.Linear(x.numel() // x.size(0), 128).to(x.device)\n",
        "\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "    def get_activations_gradient(self):\n",
        "        return self.gradients\n",
        "\n",
        "    def get_activations(self):\n",
        "        return self.activations\n",
        "\n",
        "\n",
        "# Step 2: Define the device (CPU or GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Step 3: Define transformations for the training data\n",
        "# Standard transform for the majority class (error)\n",
        "standard_transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),  # Resize images to 32x32\n",
        "    transforms.ToTensor(),         # Convert images to PyTorch tensors\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize images\n",
        "])\n",
        "\n",
        "# Augmentation transform for the minority class (no-error)\n",
        "augmentation_transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),  # Resize images to 32x32\n",
        "    transforms.RandomHorizontalFlip(p=0.5),  # Flip horizontally with 50% probability\n",
        "    transforms.RandomRotation(degrees=10),   # Rotate by up to 10 degrees\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # Adjust brightness and contrast\n",
        "    transforms.ToTensor(),  # Convert to tensor\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize\n",
        "])\n",
        "\n",
        "\n",
        "# Step 4: Custom dataset class to apply transformations dynamically\n",
        "class CustomDataset(datasets.ImageFolder):\n",
        "    def __init__(self, root, standard_transform=None, augmentation_transform=None):\n",
        "        super().__init__(root)\n",
        "        self.standard_transform = standard_transform\n",
        "        self.augmentation_transform = augmentation_transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        path, label = self.imgs[index]\n",
        "        image = Image.open(path).convert(\"RGB\")  # Ensure image is in RGB format\n",
        "\n",
        "        # Apply augmentation to the minority class (no-error)\n",
        "        if label == 1 and self.augmentation_transform:\n",
        "            image = self.augmentation_transform(image)\n",
        "        else:\n",
        "            image = self.standard_transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Step 5: Define the UnlabeledDataset class for test data\n",
        "class UnlabeledDataset(Dataset):\n",
        "    def __init__(self, root, transform=None):\n",
        "        self.root = root\n",
        "        self.transform = transform\n",
        "        self.image_paths = sorted([os.path.join(root, fname) for fname in os.listdir(root) if fname.endswith(('.jpg', '.png', '.jpeg'))])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        image = Image.open(image_path).convert(\"RGB\")  # Ensure image is in RGB format\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, os.path.basename(image_path)  # Return image and filename\n",
        "\n",
        "# Step 6: Load the training dataset\n",
        "train_data_dir = \"/content/drive/MyDrive/E-RAU(DB)/MA680/data/Shooting/Processed_Frames/TrainingKeypoints\"\n",
        "train_dataset = CustomDataset(\n",
        "    root=train_data_dir,\n",
        "    standard_transform=standard_transform,\n",
        "    augmentation_transform=augmentation_transform\n",
        ")\n",
        "\n",
        "# Debug: Print dataset size\n",
        "print(f\"Total dataset size: {len(train_dataset)}\")\n",
        "\n",
        "# Step 7: Calculate class weights for handling imbalance\n",
        "class_counts = Counter([label for _, label in train_dataset])\n",
        "total_samples = sum(class_counts.values())\n",
        "class_weights = [total_samples / class_counts[i] for i in range(len(class_counts))]\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
        "\n",
        "print(f\"Class weights: {class_weights}\")\n",
        "\n",
        "# Step 8: Calculate sample weights for the entire dataset\n",
        "sample_weights = [class_weights[label] for _, label in train_dataset]\n",
        "print(f\"Sample weights length: {len(sample_weights)}\")\n",
        "\n",
        "# Step 9: Split the dataset into training and validation sets\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "print(f\"Train size: {train_size}, Validation size: {val_size}\")\n",
        "\n",
        "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "# Step 10: Create a sampler for the training subset\n",
        "train_indices = train_dataset.indices\n",
        "train_sample_weights = [sample_weights[i] for i in train_indices]\n",
        "sampler = WeightedRandomSampler(train_sample_weights, num_samples=len(train_dataset), replacement=True)\n",
        "\n",
        "# Step 11: Create DataLoader for the training set with the sampler\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, sampler=sampler)\n",
        "\n",
        "# Step 12: Create DataLoader for the validation set\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Step 13: Define the loss function with class weights\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "# Step 14: Define the optimizer and learning rate scheduler\n",
        "model = CNN(num_classes=2).to(device)  # 2 classes: 0.Error and 1.NoError\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)  # Reduce LR every 5 epochs\n",
        "\n",
        "# Step 15: Training loop with early stopping\n",
        "num_epochs = 10\n",
        "best_val_loss = float('inf')\n",
        "patience = 3\n",
        "trigger_times = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Learning rate scheduling\n",
        "    scheduler.step()\n",
        "\n",
        "    # Print training loss\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}\")\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Compute validation metrics\n",
        "    val_loss /= len(val_loader)\n",
        "    val_accuracy = accuracy_score(all_labels, all_preds)\n",
        "    val_precision = precision_score(all_labels, all_preds, average='binary', pos_label=1)\n",
        "    val_recall = recall_score(all_labels, all_preds, average='binary', pos_label=1)\n",
        "    val_f1 = f1_score(all_labels, all_preds, average='binary', pos_label=1)\n",
        "    print(f\"Validation Loss: {val_loss:.4f}, \"\n",
        "          f\"Accuracy: {val_accuracy:.4f}, Precision: {val_precision:.4f}, \"\n",
        "          f\"Recall: {val_recall:.4f}, F1: {val_f1:.4f}\")\n",
        "\n",
        "    # Early stopping\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        trigger_times = 0\n",
        "        torch.save(model.state_dict(), \"best_model.pth\")  # Save the best model\n",
        "    else:\n",
        "        trigger_times += 1\n",
        "        if trigger_times >= patience:\n",
        "            print(\"Early stopping!\")\n",
        "            break\n",
        "\n",
        "print(\"Training complete!\")\n",
        "\n",
        "# Step 16: Grad-CAM Implementation\n",
        "def grad_cam(model, image, target_class=None):\n",
        "    \"\"\"\n",
        "    Generate a Grad-CAM heatmap for a given image and model.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    image = image.unsqueeze(0).to(device)  # Add batch dimension\n",
        "    image.requires_grad = True  # Enable gradient computation\n",
        "\n",
        "    # Forward pass\n",
        "    output = model(image)\n",
        "    if target_class is None:\n",
        "        target_class = output.argmax(dim=1).item()  # Use predicted class if target_class is None\n",
        "\n",
        "    # Backward pass to get gradients\n",
        "    model.zero_grad()\n",
        "    output[0, target_class].backward()\n",
        "\n",
        "    # Get activations and gradients\n",
        "    activations = model.get_activations().cpu().detach().numpy()  # Shape: (batch_size, channels, height, width)\n",
        "    gradients = model.get_activations_gradient().cpu().detach().numpy()  # Shape: (batch_size, channels, height, width)\n",
        "\n",
        "    # Compute the weights (global average pooling of gradients)\n",
        "    weights = np.mean(gradients, axis=(2, 3))  # Shape: (batch_size, channels)\n",
        "\n",
        "    # Compute the Grad-CAM heatmap\n",
        "    heatmap = np.zeros(activations.shape[2:], dtype=np.float32)  # Shape: (height, width)\n",
        "    for i in range(activations.shape[1]):  # Iterate over channels\n",
        "        heatmap += weights[0, i] * activations[0, i]\n",
        "\n",
        "    # Apply ReLU to the heatmap\n",
        "    heatmap = np.maximum(heatmap, 0)\n",
        "\n",
        "    # Normalize the heatmap\n",
        "    heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min())\n",
        "\n",
        "    return heatmap\n",
        "\n",
        "def visualize_gradcam(image, heatmap, alpha=0.5):\n",
        "    \"\"\"\n",
        "    Overlay the Grad-CAM heatmap on the original image with a color bar.\n",
        "\n",
        "    Args:\n",
        "        image: Original image (PyTorch tensor or PIL image).\n",
        "        heatmap: Grad-CAM heatmap (numpy array).\n",
        "        alpha: Transparency of the heatmap.\n",
        "\n",
        "    Returns:\n",
        "        None (displays the visualization).\n",
        "    \"\"\"\n",
        "    # Convert image to numpy array if it's a PyTorch tensor\n",
        "    if isinstance(image, torch.Tensor):\n",
        "        image = image.cpu().numpy()  # Convert to NumPy array\n",
        "        image = np.transpose(image, (1, 2, 0))  # Change shape from (C, H, W) to (H, W, C)\n",
        "        image = (image * 255).astype(np.uint8)  # Scale to [0, 255] and convert to uint8\n",
        "\n",
        "    # Upsample the heatmap to match the original image size\n",
        "    heatmap = cv2.resize(heatmap, (image.shape[1], image.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "    # Normalize the heatmap to [0, 1] for better visualization\n",
        "    heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min())\n",
        "\n",
        "    # Convert heatmap to 0-255 range and apply colormap\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "\n",
        "    # Overlay the heatmap on the image\n",
        "    superimposed_img = cv2.addWeighted(image, 1 - alpha, heatmap, alpha, 0)\n",
        "\n",
        "    # Display the result with a color bar\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(superimposed_img)\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Add color bar\n",
        "    cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "    cbar.set_label(\"Importance\", rotation=270, labelpad=15)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Step 17: Visualize Grad-CAM for a sample image\n",
        "sample_image, sample_label = train_dataset[0]  # Replace with your dataset\n",
        "heatmap = grad_cam(model, sample_image)\n",
        "visualize_gradcam(sample_image, heatmap)"
      ],
      "metadata": {
        "id": "DqW9_dL5AEi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluate"
      ],
      "metadata": {
        "id": "xoHYIVh2SIyb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the test dataset\n",
        "test_data_dir = \"/content/drive/MyDrive/E-RAU(DB)/MA680/data/Shooting/Processed_Frames/X.Test/Frames\"\n",
        "test_dataset = UnlabeledDataset(root=test_data_dir, transform=standard_transform)\n",
        "\n",
        "# Create a DataLoader for the test dataset\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Load the best model (if not already loaded)\n",
        "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
        "model.eval()\n",
        "\n",
        "# Initialize lists to store predictions and filenames\n",
        "all_preds = []\n",
        "all_filenames = []\n",
        "\n",
        "# Run the model on the test dataset (0 indicates error, 1 indicates no errro)\n",
        "with torch.no_grad():\n",
        "    for images, filenames in test_loader:\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_filenames.extend(filenames)\n",
        "\n",
        "# Save predictions to a CSV file\n",
        "results = pd.DataFrame({\"Filename\": all_filenames, \"Prediction\": all_preds})\n",
        "results.to_csv(\"test_predictions.csv\", index=False)\n",
        "print(\"Test predictions saved to test_predictions.csv\")\n",
        "\n",
        "# Load ground truth labels (if available)\n",
        "# Replace this with your actual ground truth labels\n",
        "ground_truth_labels = [...]  # List of labels corresponding to the test images\n",
        "\n",
        "# Compute evaluation metrics\n",
        "if len(ground_truth_labels) == len(all_preds):\n",
        "    accuracy = accuracy_score(ground_truth_labels, all_preds)\n",
        "    precision = precision_score(ground_truth_labels, all_preds, average='binary', pos_label=1)\n",
        "    recall = recall_score(ground_truth_labels, all_preds, average='binary', pos_label=1)\n",
        "    f1 = f1_score(ground_truth_labels, all_preds, average='binary', pos_label=1)\n",
        "\n",
        "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Test Precision: {precision:.4f}\")\n",
        "    print(f\"Test Recall: {recall:.4f}\")\n",
        "    print(f\"Test F1-Score: {f1:.4f}\")\n",
        "else:\n",
        "    print(\"Ground truth labels not provided or do not match predictions.\")\n",
        "\n",
        "# Visualize Grad-CAM for a few test images\n",
        "num_samples = 20  # Number of test images to visualize\n",
        "for i in range(num_samples):\n",
        "    sample_image, sample_filename = test_dataset[i]\n",
        "    heatmap = grad_cam(model, sample_image)\n",
        "    visualize_gradcam(sample_image, heatmap)\n",
        "    print(f\"Filename: {sample_filename}, Prediction: {all_preds[i]}\")"
      ],
      "metadata": {
        "id": "kvjKg5PTOffX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SXZ-vaMnOhfj"
      }
    }
  ]
}