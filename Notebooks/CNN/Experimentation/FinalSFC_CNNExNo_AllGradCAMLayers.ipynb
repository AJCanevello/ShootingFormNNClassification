{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUNIbSN3rW58"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler, random_split, Dataset\n",
        "from torchvision import transforms, datasets, models\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from collections import Counter\n",
        "from PIL import Image\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Define the ResNet18 model with Grad-CAM support for multiple layers\n",
        "class ResNetWithGradCAM(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ResNetWithGradCAM, self).__init__()\n",
        "        self.model = models.resnet18(pretrained=True)\n",
        "        self.num_features = self.model.fc.in_features\n",
        "        self.model.fc = nn.Linear(self.num_features, num_classes)  # Modify the final layer\n",
        "\n",
        "        # Dictionary to store activations and gradients for different layers\n",
        "        self.layer_data = {\n",
        "            'layer1': {'activations': None, 'gradients': None},\n",
        "            'layer2': {'activations': None, 'gradients': None},\n",
        "            'layer3': {'activations': None, 'gradients': None},\n",
        "            'layer4': {'activations': None, 'gradients': None}\n",
        "        }\n",
        "\n",
        "        # Register hooks for all layers\n",
        "        self.model.layer1.register_forward_hook(self.create_hook('layer1'))\n",
        "        self.model.layer1.register_backward_hook(self.create_grad_hook('layer1'))\n",
        "        self.model.layer2.register_forward_hook(self.create_hook('layer2'))\n",
        "        self.model.layer2.register_backward_hook(self.create_grad_hook('layer2'))\n",
        "        self.model.layer3.register_forward_hook(self.create_hook('layer3'))\n",
        "        self.model.layer3.register_backward_hook(self.create_grad_hook('layer3'))\n",
        "        self.model.layer4.register_forward_hook(self.create_hook('layer4'))\n",
        "        self.model.layer4.register_backward_hook(self.create_grad_hook('layer4'))\n",
        "\n",
        "    def create_hook(self, layer_name):\n",
        "        def hook(module, input, output):\n",
        "            self.layer_data[layer_name]['activations'] = output\n",
        "        return hook\n",
        "\n",
        "    def create_grad_hook(self, layer_name):\n",
        "        def hook(module, grad_input, grad_output):\n",
        "            self.layer_data[layer_name]['gradients'] = grad_output[0]\n",
        "        return hook\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def get_activations(self, layer_name):\n",
        "        return self.layer_data[layer_name]['activations']\n",
        "\n",
        "    def get_gradients(self, layer_name):\n",
        "        return self.layer_data[layer_name]['gradients']\n",
        "\n",
        "# Step 2: Define the device (CPU or GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Step 3: Define transformations\n",
        "standard_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "augmentation_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Step 4: Custom dataset class\n",
        "class CustomDataset(datasets.ImageFolder):\n",
        "    def __init__(self, root, standard_transform=None, augmentation_transform=None):\n",
        "        super().__init__(root)\n",
        "        self.standard_transform = standard_transform\n",
        "        self.augmentation_transform = augmentation_transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        path, label = self.imgs[index]\n",
        "        image = Image.open(path).convert(\"RGB\")\n",
        "\n",
        "        if label == 1 and self.augmentation_transform:\n",
        "            image = self.augmentation_transform(image)\n",
        "        else:\n",
        "            image = self.standard_transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Step 5: Define the UnlabeledDataset class\n",
        "class UnlabeledDataset(Dataset):\n",
        "    def __init__(self, root, transform=None):\n",
        "        self.root = root\n",
        "        self.transform = transform\n",
        "        self.image_paths = sorted([os.path.join(root, fname) for fname in os.listdir(root) if fname.endswith(('.jpg', '.png', '.jpeg'))])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, os.path.basename(image_path)\n",
        "\n",
        "# Step 6: Load the training dataset\n",
        "train_data_dir = \"/content/drive/MyDrive/E-RAU(DB)/MA680/data/Shooting/Processed_Frames/TrainingImages\"\n",
        "train_dataset = CustomDataset(\n",
        "    root=train_data_dir,\n",
        "    standard_transform=standard_transform,\n",
        "    augmentation_transform=augmentation_transform\n",
        ")\n",
        "\n",
        "print(f\"Total dataset size: {len(train_dataset)}\")\n",
        "\n",
        "# Step 7: Calculate class weights\n",
        "class_counts = Counter([label for _, label in train_dataset])\n",
        "total_samples = sum(class_counts.values())\n",
        "class_weights = [total_samples / class_counts[i] for i in range(len(class_counts))]\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "print(f\"Class weights: {class_weights}\")\n",
        "\n",
        "# Step 8: Calculate sample weights\n",
        "sample_weights = [class_weights[label] for _, label in train_dataset]\n",
        "print(f\"Sample weights length: {len(sample_weights)}\")\n",
        "\n",
        "# Step 9: Split the dataset\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "print(f\"Train size: {train_size}, Validation size: {val_size}\")\n",
        "\n",
        "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "# Step 10: Create sampler for training subset\n",
        "train_indices = train_dataset.indices\n",
        "train_sample_weights = [sample_weights[i] for i in train_indices]\n",
        "sampler = WeightedRandomSampler(train_sample_weights, num_samples=len(train_dataset), replacement=True)\n",
        "\n",
        "# Step 11: Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, sampler=sampler)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Step 12: Initialize model\n",
        "model = ResNetWithGradCAM(num_classes=2).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "\n",
        "# Step 13: Training loop\n",
        "num_epochs = 10\n",
        "best_val_loss = float('inf')\n",
        "patience = 3\n",
        "trigger_times = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    scheduler.step()\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "    val_accuracy = accuracy_score(all_labels, all_preds)\n",
        "    val_precision = precision_score(all_labels, all_preds, average='binary', pos_label=1)\n",
        "    val_recall = recall_score(all_labels, all_preds, average='binary', pos_label=1)\n",
        "    val_f1 = f1_score(all_labels, all_preds, average='binary', pos_label=1)\n",
        "    print(f\"Validation Loss: {val_loss:.4f}, \"\n",
        "          f\"Accuracy: {val_accuracy:.4f}, Precision: {val_precision:.4f}, \"\n",
        "          f\"Recall: {val_recall:.4f}, F1: {val_f1:.4f}\")\n",
        "\n",
        "    # Early stopping\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        trigger_times = 0\n",
        "        torch.save(model.state_dict(), \"best_pretrained_model.pth\")\n",
        "    else:\n",
        "        trigger_times += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 14: Enhanced Multi-Layer Grad-CAM Implementation\n",
        "def grad_cam_multi_layer(model, image, layer_name, class_idx=None):\n",
        "    \"\"\"Generate Grad-CAM heatmap for a specific layer\"\"\"\n",
        "    model.eval()\n",
        "    image = image.unsqueeze(0).to(device)\n",
        "    image.requires_grad = True\n",
        "\n",
        "    # Forward pass\n",
        "    output = model(image)\n",
        "    probs = torch.softmax(output, dim=1)\n",
        "\n",
        "    if class_idx is None:\n",
        "        class_idx = torch.argmax(output, dim=1).item()\n",
        "\n",
        "    # Zero gradients\n",
        "    model.zero_grad()\n",
        "\n",
        "    # Create one-hot encoding\n",
        "    one_hot = torch.zeros_like(output)\n",
        "    one_hot[0, class_idx] = 1\n",
        "\n",
        "    # Backpropagate\n",
        "    output.backward(gradient=one_hot)\n",
        "\n",
        "    # Get activations and gradients\n",
        "    activations = model.get_activations(layer_name).cpu().detach().numpy()\n",
        "    gradients = model.get_gradients(layer_name).cpu().detach().numpy()\n",
        "\n",
        "    # Compute weights\n",
        "    weights = np.mean(gradients, axis=(2, 3))\n",
        "\n",
        "    # Create heatmap\n",
        "    heatmap = np.zeros(activations.shape[2:], dtype=np.float32)\n",
        "    for i in range(activations.shape[1]):\n",
        "        heatmap += weights[0, i] * activations[0, i]\n",
        "\n",
        "    heatmap = np.maximum(heatmap, 0)\n",
        "    heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min() + 1e-8)\n",
        "\n",
        "    return heatmap, probs[0].cpu().detach().numpy()\n",
        "\n",
        "def visualize_multi_layer_gradcam(image, layer_results, pred_prob):\n",
        "    \"\"\"Visualize Grad-CAM results from multiple layers with color gradient key\"\"\"\n",
        "    if isinstance(image, torch.Tensor):\n",
        "        image = image.cpu().numpy()\n",
        "        image = np.transpose(image, (1, 2, 0))\n",
        "        # Denormalize\n",
        "        mean = np.array([0.485, 0.456, 0.406])\n",
        "        std = np.array([0.229, 0.224, 0.225])\n",
        "        image = std * image + mean\n",
        "        image = np.clip(image, 0, 1)\n",
        "        image = (image * 255).astype(np.uint8)\n",
        "\n",
        "    num_layers = len(layer_results)\n",
        "    # Create figure with additional space for colorbar\n",
        "    fig = plt.figure(figsize=(5*(num_layers+1)+1, 6))  # Extra space for colorbar\n",
        "    gs = fig.add_gridspec(2, num_layers+1, height_ratios=[20, 1], width_ratios=[1]*num_layers + [0.2])\n",
        "\n",
        "    # Original image\n",
        "    ax0 = fig.add_subplot(gs[0, 0])\n",
        "    ax0.imshow(image)\n",
        "    ax0.set_title(f\"Original\\nPred: {'Good' if pred_prob[1] > 0.5 else 'Bad'}\")\n",
        "    ax0.axis('off')\n",
        "\n",
        "    # Each layer's heatmap\n",
        "    for i, (layer_name, heatmap) in enumerate(layer_results.items(), 1):\n",
        "        ax = fig.add_subplot(gs[0, i])\n",
        "        heatmap = cv2.resize(heatmap, (image.shape[1], image.shape[0]))\n",
        "        heatmap_viz = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n",
        "        overlay = cv2.addWeighted(image, 0.5, heatmap_viz, 0.5, 0)\n",
        "\n",
        "        ax.imshow(overlay)\n",
        "        ax.set_title(f\"{layer_name}\\nResolution: {heatmap.shape}\")\n",
        "        ax.axis('off')\n",
        "\n",
        "    # Add colorbar\n",
        "    cax = fig.add_subplot(gs[1, :])  # Span across all columns in bottom row\n",
        "    cmap = plt.get_cmap('jet')\n",
        "    norm = plt.Normalize(vmin=0, vmax=1)\n",
        "    cb = fig.colorbar(plt.cm.ScalarMappable(norm=norm, cmap=cmap),\n",
        "                     cax=cax, orientation='horizontal')\n",
        "    cb.set_label('Activation Intensity', labelpad=5)\n",
        "    cax.xaxis.set_ticks_position('top')\n",
        "    cax.xaxis.set_label_position('top')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Step 15: Test the Multi-Layer Grad-CAM visualization\n",
        "sample_image, sample_label = train_dataset[0]\n",
        "target_layers = ['layer1', 'layer2', 'layer3', 'layer4']  # From shallow to deep\n",
        "layer_results = {}\n",
        "\n",
        "for layer_name in target_layers:\n",
        "    heatmap, probs = grad_cam_multi_layer(model, sample_image, layer_name)\n",
        "    layer_results[layer_name] = heatmap\n",
        "\n",
        "visualize_multi_layer_gradcam(sample_image, layer_results, probs)\n",
        "\n",
        "# Step 16: Test dataset evaluation\n",
        "test_data_dir = \"/content/drive/MyDrive/E-RAU(DB)/MA680/data/Shooting/Processed_Frames/X.Test/Frames\"\n",
        "test_dataset = UnlabeledDataset(root=test_data_dir, transform=standard_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Load best model\n",
        "model.load_state_dict(torch.load(\"best_pretrained_model.pth\"))\n",
        "model.eval()\n",
        "\n",
        "# Initialize lists\n",
        "all_preds = []\n",
        "all_filenames = []\n",
        "\n",
        "# Run predictions\n",
        "with torch.no_grad():\n",
        "    for images, filenames in test_loader:\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_filenames.extend(filenames)\n",
        "\n",
        "# Save predictions\n",
        "results = pd.DataFrame({\"Filename\": all_filenames, \"Prediction\": all_preds})\n",
        "results.to_csv(\"test_predictions.csv\", index=False)\n",
        "print(\"Test predictions saved to test_predictions.csv\")\n",
        "\n",
        "# Step 17: Visualize Grad-CAM for test images at multiple layers\n",
        "num_samples = 50  # Number of test images to visualize\n",
        "target_layers = ['layer1', 'layer2', 'layer3', 'layer4']  # From shallow to deep\n",
        "\n",
        "for i in range(min(num_samples, len(test_dataset))):\n",
        "    sample_image, sample_filename = test_dataset[i]\n",
        "    layer_results = {}\n",
        "\n",
        "    for layer_name in target_layers:\n",
        "        heatmap, probs = grad_cam_multi_layer(model, sample_image, layer_name)\n",
        "        layer_results[layer_name] = heatmap\n",
        "\n",
        "    visualize_multi_layer_gradcam(sample_image, layer_results, probs)\n",
        "    print(f\"Filename: {sample_filename}, Prediction: {'Good' if all_preds[i] == 1 else 'Bad'}\")"
      ],
      "metadata": {
        "id": "4yoDZStiwAuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JE2ywyZv5kTW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}