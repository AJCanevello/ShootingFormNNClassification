{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install all required packages with version control\n",
        "!pip install captum torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.2.0+cu121.html"
      ],
      "metadata": {
        "id": "kc9B5mvFbogA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Detect environment\n",
        "import torch\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "cuda_version = torch.version.cuda.replace('.', '') if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Install matching PyG packages\n",
        "pyg_url = f\"https://data.pyg.org/whl/torch-{torch.__version__}+cu{cuda_version}.html\"\n",
        "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f {pyg_url}\n",
        "\n",
        "# Verify\n",
        "try:\n",
        "    from torch_geometric.nn import GCNConv\n",
        "    print(\"\\nSUCCESS: PyTorch Geometric installed correctly!\")\n",
        "except ImportError as e:\n",
        "    print(\"\\nERROR:\", e)\n",
        "    print(\"Try manually specifying versions above\")"
      ],
      "metadata": {
        "id": "gXmFxcCzbkDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVLRB8KObh2K"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "from torch_geometric.utils import to_networkx\n",
        "from matplotlib.colors import Normalize\n",
        "from PIL import Image\n",
        "from matplotlib.gridspec import GridSpec\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Define paths\n",
        "base_graph_dir = \"/content/drive/MyDrive/E-RAU(DB)/MA680/data/Shooting/Processed_Graph_Data/GraphFolders\"\n",
        "base_frame_dir = \"/content/drive/MyDrive/E-RAU(DB)/MA680/data/Shooting/Processed_Frames/ImageFolders\"\n",
        "train_graph_dir = os.path.join(base_graph_dir, \"TrainGraphFolders\")\n",
        "train_frame_dir = os.path.join(base_frame_dir, \"TrainImageFolders\")\n",
        "\n",
        "# 1. Enhanced Dataset Class with Image-Graph pairing\n",
        "class PoseGraphDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, graph_dir, frame_dir, mode='train'):\n",
        "        self.graph_dir = graph_dir\n",
        "        self.frame_dir = frame_dir\n",
        "        self.mode = mode\n",
        "        self.samples = []\n",
        "        self.body_part_labels = self._create_body_part_labels()\n",
        "\n",
        "        if mode == 'train':\n",
        "            self._load_train_data()\n",
        "        else:\n",
        "            self._load_test_data()\n",
        "\n",
        "        print(f\"Loaded {len(self.samples)} {mode} samples\")\n",
        "\n",
        "    def _create_body_part_labels(self):\n",
        "        \"\"\"Create labels for key body parts\"\"\"\n",
        "        labels = {\n",
        "            0: \"Nose\", 1: \"L Eye\", 2: \"R Eye\", 3: \"L Ear\", 4: \"R Ear\",\n",
        "            5: \"L Shoulder\", 6: \"R Shoulder\", 7: \"L Elbow\", 8: \"R Elbow\",\n",
        "            9: \"L Wrist\", 10: \"R Wrist\", 11: \"L Hip\", 12: \"R Hip\",\n",
        "            13: \"L Knee\", 14: \"R Knee\", 15: \"L Ankle\", 16: \"R Ankle\"\n",
        "        }\n",
        "        # Add hands (simplified)\n",
        "        for i in range(33, 54):\n",
        "            labels[i] = f\"L Hand {i-33}\"\n",
        "        for i in range(54, 75):\n",
        "            labels[i] = f\"R Hand {i-54}\"\n",
        "        return labels\n",
        "\n",
        "    def _find_corresponding_frame(self, json_path):\n",
        "        \"\"\"Find the corresponding image frame for a graph JSON file\"\"\"\n",
        "        parts = json_path.split('/')\n",
        "        video_folder = parts[-2]\n",
        "        frame_num = parts[-1].split('_')[1].split('.')[0]\n",
        "\n",
        "        if \"ErrorGraphFolders\" in json_path:\n",
        "            frame_dir = os.path.join(self.frame_dir, \"ErrorImageFolders\", video_folder)\n",
        "        elif \"NoErrorGraphFolders\" in json_path:\n",
        "            frame_dir = os.path.join(self.frame_dir, \"NoErrorImageFolders\", video_folder)\n",
        "        else:\n",
        "            frame_dir = os.path.join(self.frame_dir, \"TestImageFolders\", video_folder)\n",
        "\n",
        "        frame_path = os.path.join(frame_dir, f\"frame_{frame_num}.jpg\")\n",
        "        return frame_path if os.path.exists(frame_path) else None\n",
        "\n",
        "    def _load_train_data(self):\n",
        "        \"\"\"Load training data with image-graph pairs\"\"\"\n",
        "        for class_folder in [\"ErrorGraphFolders\", \"NoErrorGraphFolders\"]:\n",
        "            class_dir = os.path.join(self.graph_dir, class_folder)\n",
        "            label = 0 if \"Error\" in class_folder else 1\n",
        "\n",
        "            for video_folder in os.listdir(class_dir):\n",
        "                video_path = os.path.join(class_dir, video_folder)\n",
        "                if os.path.isdir(video_path):\n",
        "                    for json_file in os.listdir(video_path):\n",
        "                        if json_file.endswith('.json'):\n",
        "                            json_path = os.path.join(video_path, json_file)\n",
        "                            frame_path = self._find_corresponding_frame(json_path)\n",
        "                            if frame_path:\n",
        "                                self.samples.append((json_path, frame_path, label))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        json_path, frame_path, label = self.samples[idx]\n",
        "\n",
        "        try:\n",
        "            with open(json_path, 'r') as f:\n",
        "                graph_data = json.load(f)\n",
        "\n",
        "            x = torch.tensor(graph_data['nodes'], dtype=torch.float)\n",
        "            edge_index = torch.tensor(graph_data['edges'], dtype=torch.long).t().contiguous()\n",
        "\n",
        "            return Data(\n",
        "                x=x,\n",
        "                edge_index=edge_index,\n",
        "                y=torch.tensor([label], dtype=torch.long),\n",
        "                frame_path=frame_path,\n",
        "                body_part_labels=self.body_part_labels\n",
        "            )\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {json_path}: {str(e)}\")\n",
        "            return Data(\n",
        "                x=torch.zeros((75, 3), dtype=torch.float),\n",
        "                edge_index=torch.zeros((2, 1), dtype=torch.long),\n",
        "                y=torch.tensor([label], dtype=torch.long),\n",
        "                frame_path=\"\",\n",
        "                body_part_labels=self.body_part_labels\n",
        "            )\n",
        "\n",
        "# 2. Define ExplainableGCN Model\n",
        "class ExplainableGCN(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(ExplainableGCN, self).__init__()\n",
        "        self.conv1 = GCNConv(3, 64)\n",
        "        self.conv2 = GCNConv(64, 128)\n",
        "        self.conv3 = GCNConv(128, 256)\n",
        "        self.fc = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        x = F.relu(self.conv3(x, edge_index))\n",
        "\n",
        "        x = global_mean_pool(x, batch)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "    def compute_node_importance(self, data):\n",
        "        \"\"\"Compute node importance using gradients\"\"\"\n",
        "        data = data.clone().to(device)\n",
        "        data.x.requires_grad_(True)\n",
        "\n",
        "        self.eval()\n",
        "        output = self(data)\n",
        "        pred_class = output.argmax(dim=1).item()\n",
        "\n",
        "        self.zero_grad()\n",
        "        output[0, pred_class].backward()\n",
        "\n",
        "        if data.x.grad is not None:\n",
        "            gradients = data.x.grad.abs().mean(dim=1)\n",
        "            return gradients, pred_class\n",
        "        else:\n",
        "            return torch.zeros(data.x.size(0)), pred_class\n",
        "\n",
        "# 4. Initialize dataset\n",
        "train_dataset = PoseGraphDataset(train_graph_dir, train_frame_dir, mode='train')\n",
        "\n",
        "# 3. Visualization function\n",
        "def visualize_graph_with_image(data, importance, pred_class):\n",
        "    \"\"\"Improved visualization that handles upper-body shots and correct labeling\"\"\"\n",
        "    fig = plt.figure(figsize=(24, 10))\n",
        "    gs = GridSpec(1, 2, width_ratios=[1, 1])\n",
        "\n",
        "    try:\n",
        "        # 1. GRAPH VISUALIZATION\n",
        "        ax1 = plt.subplot(gs[0])\n",
        "        G = nx.Graph()\n",
        "        for i in range(data.x.size(0)):\n",
        "            G.add_node(i)\n",
        "        edge_list = data.edge_index.t().tolist()\n",
        "        G.add_edges_from(edge_list)\n",
        "\n",
        "        # Use normalized coordinates with proper aspect ratio\n",
        "        x_coords = data.x[:,0].cpu().numpy()\n",
        "        y_coords = 1 - data.x[:,1].cpu().numpy()  # Flip y-axis\n",
        "\n",
        "        # Center and scale coordinates\n",
        "        x_min, x_max = x_coords.min(), x_coords.max()\n",
        "        y_min, y_max = y_coords.min(), y_coords.max()\n",
        "\n",
        "        # Handle upper-body shots (no legs visible)\n",
        "        if y_max - y_min < 0.3:  # If vertical range is small\n",
        "            y_min = 0  # Extend to full height\n",
        "            y_max = 1\n",
        "\n",
        "        pos = {i: (x_coords[i], y_coords[i]) for i in range(len(x_coords))}\n",
        "\n",
        "        # Normalize importance\n",
        "        importance_norm = (importance - importance.min()) / (importance.max() - importance.min() + 1e-9)\n",
        "\n",
        "        # Draw only major body parts (skip hand/finger joints for clarity)\n",
        "        visible_nodes = [i for i in pos.keys() if i < 33]  # Only pose keypoints\n",
        "        subgraph = G.subgraph(visible_nodes)\n",
        "        sub_pos = {k: pos[k] for k in visible_nodes}\n",
        "        sub_importance = importance_norm[:33]\n",
        "\n",
        "        # Draw graph\n",
        "        nx.draw_networkx_nodes(\n",
        "            subgraph, sub_pos,\n",
        "            node_color=sub_importance.cpu().numpy(),\n",
        "            cmap=plt.cm.Reds,\n",
        "            node_size=300,\n",
        "            alpha=0.8,\n",
        "            ax=ax1\n",
        "        )\n",
        "\n",
        "        # Draw only major connections\n",
        "        major_edges = [\n",
        "            (0,1),(0,2),(1,3),(2,4),        # Head\n",
        "            (5,6),(5,7),(6,8),(7,9),(8,10),  # Arms\n",
        "            (5,11),(6,12),(11,12),(11,13),(12,14),(13,15),(14,16)  # Torso and legs\n",
        "        ]\n",
        "\n",
        "        nx.draw_networkx_edges(\n",
        "            subgraph, sub_pos,\n",
        "            edgelist=major_edges,\n",
        "            edge_color='gray',\n",
        "            width=2,\n",
        "            alpha=0.5,\n",
        "            ax=ax1\n",
        "        )\n",
        "\n",
        "        # Correct body part labels (MediaPipe standard indices)\n",
        "        body_part_labels = {\n",
        "    0: \"Nose\", 1: \"Left Eye Inner\", 2: \"Left Eye\", 3: \"Left Eye Outer\",\n",
        "    4: \"Right Eye Inner\", 5: \"Right Eye\", 6: \"Right Eye Outer\",\n",
        "    7: \"Left Ear\", 8: \"Right Ear\", 9: \"Mouth Left\", 10: \"Mouth Right\",\n",
        "    11: \"Left Shoulder\", 12: \"Right Shoulder\", 13: \"Left Elbow\",\n",
        "    14: \"Right Elbow\", 15: \"Left Wrist\", 16: \"Right Wrist\",\n",
        "    17: \"Left Pinky\", 18: \"Right Pinky\", 19: \"Left Index\",\n",
        "    20: \"Right Index\", 21: \"Left Thumb\", 22: \"Right Thumb\",\n",
        "    23: \"Left Hip\", 24: \"Right Hip\", 25: \"Left Knee\", 26: \"Right Knee\",\n",
        "    27: \"Left Ankle\", 28: \"Right Ankle\", 29: \"Left Heel\", 30: \"Right Heel\",\n",
        "    31: \"Left Foot Index\", 32: \"Right Foot Index\"\n",
        "}\n",
        "\n",
        "        # Label only key joints\n",
        "        key_joints = [0,5,6,7,8,11,12,13,14]\n",
        "        labels = {i: body_part_labels.get(i, \"\") for i in key_joints if i in sub_pos}\n",
        "        nx.draw_networkx_labels(\n",
        "            subgraph, sub_pos,\n",
        "            labels=labels,\n",
        "            font_size=12,\n",
        "            font_weight='bold',\n",
        "            ax=ax1\n",
        "        )\n",
        "\n",
        "        ax1.set_title(f\"Body Graph Importance\\nPredicted: {'Error' if pred_class == 0 else 'NoError'}\", fontsize=14)\n",
        "        ax1.set_xlim(0, 1)\n",
        "        ax1.set_ylim(0, 1)\n",
        "        ax1.axis('off')\n",
        "\n",
        "        # 2. IMAGE VISUALIZATION\n",
        "        ax2 = plt.subplot(gs[1])\n",
        "        if hasattr(data, 'frame_path') and os.path.exists(data.frame_path):\n",
        "            img = Image.open(data.frame_path)\n",
        "            ax2.imshow(img)\n",
        "\n",
        "            # Overlay keypoints on image\n",
        "            for i, (x, y) in sub_pos.items():\n",
        "                if i in body_part_labels:\n",
        "                    ax2.scatter(\n",
        "                        x * img.width,\n",
        "                        y * img.height,\n",
        "                        s=50,\n",
        "                        c='red' if importance_norm[i] > 0.5 else 'blue',\n",
        "                        alpha=0.7\n",
        "                    )\n",
        "                    if i in key_joints:\n",
        "                        ax2.text(\n",
        "                            x * img.width + 10,\n",
        "                            y * img.height + 10,\n",
        "                            body_part_labels[i],\n",
        "                            color='white',\n",
        "                            fontsize=12,\n",
        "                            bbox=dict(facecolor='black', alpha=0.5)\n",
        "                        )\n",
        "\n",
        "            ax2.set_title(\"Original Frame with Keypoints\", fontsize=14)\n",
        "            ax2.axis('off')\n",
        "        else:\n",
        "            ax2.text(0.5, 0.5, \"Image not found\", ha='center', va='center')\n",
        "            ax2.axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Print importance for key joints\n",
        "        print(\"\\nKey Joint Importance Scores:\")\n",
        "        for i in sorted(key_joints):\n",
        "            if i < len(importance):\n",
        "                print(f\"{body_part_labels.get(i, f'Joint {i}'):>12}: {importance[i].item():.3f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Visualization error: {str(e)}\")\n",
        "\n",
        "# 5. Load or create model\n",
        "model = ExplainableGCN().to(device)\n",
        "\n",
        "# Example usage with your model\n",
        "sample_indices = [0, 5, 10]  # Different samples to visualize\n",
        "for idx in sample_indices:\n",
        "    if idx < len(train_dataset):\n",
        "        sample_data = train_dataset[idx].to(device)\n",
        "        node_importances, pred_class = model.compute_node_importance(sample_data)\n",
        "        visualize_graph_with_image(sample_data, node_importances, pred_class)\n",
        "\n",
        "\n",
        "# Try to load pretrained weights\n",
        "model_path = \"best_gcn_model.pth\"\n",
        "if os.path.exists(model_path):\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    print(\"Loaded pretrained model weights\")\n",
        "else:\n",
        "    print(\"Initialized new model (no pretrained weights found)\")\n",
        "\n",
        "# 6. Generate visualizations\n",
        "sample_indices = [0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100]  # Different samples to visualize\n",
        "for idx in sample_indices:\n",
        "    if idx < len(train_dataset):  # Check if index is valid\n",
        "        sample_data = train_dataset[idx].to(device)\n",
        "        node_importances, pred_class = model.compute_node_importance(sample_data)\n",
        "        visualize_graph_with_image(sample_data, node_importances, pred_class)\n",
        "    else:\n",
        "        print(f\"Skipping index {idx} - exceeds dataset size\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZhTrhiYWbsjN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}