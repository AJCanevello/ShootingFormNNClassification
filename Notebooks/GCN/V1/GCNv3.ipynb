{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install all required packages with version control\n",
        "!pip install captum torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.2.0+cu121.html"
      ],
      "metadata": {
        "id": "kc9B5mvFbogA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Detect environment\n",
        "import torch\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "cuda_version = torch.version.cuda.replace('.', '') if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Install matching PyG packages\n",
        "pyg_url = f\"https://data.pyg.org/whl/torch-{torch.__version__}+cu{cuda_version}.html\"\n",
        "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f {pyg_url}\n",
        "\n",
        "# Verify\n",
        "try:\n",
        "    from torch_geometric.nn import GCNConv\n",
        "    print(\"\\nSUCCESS: PyTorch Geometric installed correctly!\")\n",
        "except ImportError as e:\n",
        "    print(\"\\nERROR:\", e)\n",
        "    print(\"Try manually specifying versions above\")"
      ],
      "metadata": {
        "id": "gXmFxcCzbkDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVLRB8KObh2K"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "from torch_geometric.utils import to_networkx\n",
        "from matplotlib.colors import Normalize\n",
        "from PIL import Image\n",
        "from matplotlib.gridspec import GridSpec\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Define paths\n",
        "base_graph_dir = \"/content/drive/MyDrive/E-RAU(DB)/MA680/data/Shooting/Processed_Graph_Data/GraphFolders\"\n",
        "base_frame_dir = \"/content/drive/MyDrive/E-RAU(DB)/MA680/data/Shooting/Processed_Frames/ImageFolders\"\n",
        "train_graph_dir = os.path.join(base_graph_dir, \"TrainGraphFolders\")\n",
        "train_frame_dir = os.path.join(base_frame_dir, \"TrainImageFolders\")\n",
        "\n",
        "# 1. Enhanced Dataset Class with Image-Graph pairing\n",
        "class PoseGraphDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, graph_dir, frame_dir, mode='train'):\n",
        "        self.graph_dir = graph_dir\n",
        "        self.frame_dir = frame_dir\n",
        "        self.mode = mode\n",
        "        self.samples = []\n",
        "        self.body_part_labels = self._create_body_part_labels()\n",
        "\n",
        "        if mode == 'train':\n",
        "            self._load_train_data()\n",
        "        else:\n",
        "            self._load_test_data()\n",
        "\n",
        "        print(f\"Loaded {len(self.samples)} {mode} samples\")\n",
        "\n",
        "    def _create_body_part_labels(self):\n",
        "        \"\"\"Create labels for key body parts\"\"\"\n",
        "        labels = {\n",
        "            0: \"Nose\", 1: \"L Eye\", 2: \"R Eye\", 3: \"L Ear\", 4: \"R Ear\",\n",
        "            5: \"L Shoulder\", 6: \"R Shoulder\", 7: \"L Elbow\", 8: \"R Elbow\",\n",
        "            9: \"L Wrist\", 10: \"R Wrist\", 11: \"L Hip\", 12: \"R Hip\",\n",
        "            13: \"L Knee\", 14: \"R Knee\", 15: \"L Ankle\", 16: \"R Ankle\"\n",
        "        }\n",
        "        # Add hands (simplified)\n",
        "        for i in range(33, 54):\n",
        "            labels[i] = f\"L Hand {i-33}\"\n",
        "        for i in range(54, 75):\n",
        "            labels[i] = f\"R Hand {i-54}\"\n",
        "        return labels\n",
        "\n",
        "    def _find_corresponding_frame(self, json_path):\n",
        "        \"\"\"Find the corresponding image frame for a graph JSON file\"\"\"\n",
        "        parts = json_path.split('/')\n",
        "        video_folder = parts[-2]\n",
        "        frame_num = parts[-1].split('_')[1].split('.')[0]\n",
        "\n",
        "        if \"ErrorGraphFolders\" in json_path:\n",
        "            frame_dir = os.path.join(self.frame_dir, \"ErrorImageFolders\", video_folder)\n",
        "        elif \"NoErrorGraphFolders\" in json_path:\n",
        "            frame_dir = os.path.join(self.frame_dir, \"NoErrorImageFolders\", video_folder)\n",
        "        else:\n",
        "            frame_dir = os.path.join(self.frame_dir, \"TestImageFolders\", video_folder)\n",
        "\n",
        "        frame_path = os.path.join(frame_dir, f\"frame_{frame_num}.jpg\")\n",
        "        return frame_path if os.path.exists(frame_path) else None\n",
        "\n",
        "    def _load_train_data(self):\n",
        "        \"\"\"Load training data with image-graph pairs\"\"\"\n",
        "        for class_folder in [\"ErrorGraphFolders\", \"NoErrorGraphFolders\"]:\n",
        "            class_dir = os.path.join(self.graph_dir, class_folder)\n",
        "            label = 0 if \"Error\" in class_folder else 1\n",
        "\n",
        "            for video_folder in os.listdir(class_dir):\n",
        "                video_path = os.path.join(class_dir, video_folder)\n",
        "                if os.path.isdir(video_path):\n",
        "                    for json_file in os.listdir(video_path):\n",
        "                        if json_file.endswith('.json'):\n",
        "                            json_path = os.path.join(video_path, json_file)\n",
        "                            frame_path = self._find_corresponding_frame(json_path)\n",
        "                            if frame_path:\n",
        "                                self.samples.append((json_path, frame_path, label))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        json_path, frame_path, label = self.samples[idx]\n",
        "\n",
        "        try:\n",
        "            with open(json_path, 'r') as f:\n",
        "                graph_data = json.load(f)\n",
        "\n",
        "            x = torch.tensor(graph_data['nodes'], dtype=torch.float)\n",
        "            edge_index = torch.tensor(graph_data['edges'], dtype=torch.long).t().contiguous()\n",
        "\n",
        "            return Data(\n",
        "                x=x,\n",
        "                edge_index=edge_index,\n",
        "                y=torch.tensor([label], dtype=torch.long),\n",
        "                frame_path=frame_path,\n",
        "                body_part_labels=self.body_part_labels\n",
        "            )\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {json_path}: {str(e)}\")\n",
        "            return Data(\n",
        "                x=torch.zeros((75, 3), dtype=torch.float),\n",
        "                edge_index=torch.zeros((2, 1), dtype=torch.long),\n",
        "                y=torch.tensor([label], dtype=torch.long),\n",
        "                frame_path=\"\",\n",
        "                body_part_labels=self.body_part_labels\n",
        "            )\n",
        "\n",
        "# 2. Define ExplainableGCN Model\n",
        "class ExplainableGCN(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(ExplainableGCN, self).__init__()\n",
        "        self.conv1 = GCNConv(3, 64)\n",
        "        self.conv2 = GCNConv(64, 128)\n",
        "        self.conv3 = GCNConv(128, 256)\n",
        "        self.fc = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        x = F.relu(self.conv3(x, edge_index))\n",
        "\n",
        "        x = global_mean_pool(x, batch)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "    def compute_node_importance(self, data):\n",
        "        \"\"\"Compute node importance using gradients\"\"\"\n",
        "        data = data.clone().to(device)\n",
        "        data.x.requires_grad_(True)\n",
        "\n",
        "        self.eval()\n",
        "        output = self(data)\n",
        "        pred_class = output.argmax(dim=1).item()\n",
        "\n",
        "        self.zero_grad()\n",
        "        output[0, pred_class].backward()\n",
        "\n",
        "        if data.x.grad is not None:\n",
        "            gradients = data.x.grad.abs().mean(dim=1)\n",
        "            return gradients, pred_class\n",
        "        else:\n",
        "            return torch.zeros(data.x.size(0)), pred_class\n",
        "\n",
        "# 3. Visualization function\n",
        "def visualize_graph_with_image(data, importance, pred_class):\n",
        "    \"\"\"Visualize graph and corresponding image side by side\"\"\"\n",
        "    fig = plt.figure(figsize=(20, 10))\n",
        "    gs = GridSpec(1, 2, width_ratios=[1, 1])\n",
        "\n",
        "    try:\n",
        "        # Graph Visualization\n",
        "        ax1 = plt.subplot(gs[0])\n",
        "        G = to_networkx(data, to_undirected=True)\n",
        "        pos = {i: (data.x[i,0].item(), -data.x[i,1].item()) for i in range(data.x.size(0))}\n",
        "\n",
        "        importance_norm = (importance - importance.min()) / (importance.max() - importance.min() + 1e-9)\n",
        "\n",
        "        nx.draw_networkx_nodes(\n",
        "            G, pos,\n",
        "            node_color=importance_norm.cpu().numpy(),\n",
        "            cmap=plt.cm.Reds,\n",
        "            node_size=200,\n",
        "            alpha=0.8,\n",
        "            ax=ax1\n",
        "        )\n",
        "        nx.draw_networkx_edges(G, pos, alpha=0.2, ax=ax1)\n",
        "\n",
        "        top_nodes = torch.topk(importance, k=5).indices.tolist()\n",
        "        labels = {i: data.body_part_labels.get(i, f\"Node {i}\") for i in top_nodes}\n",
        "        nx.draw_networkx_labels(G, pos, labels, font_size=10, font_weight='bold', ax=ax1)\n",
        "\n",
        "        ax1.set_title(f\"Graph Importance\\nPredicted: {'Error' if pred_class == 0 else 'NoError'}\")\n",
        "        ax1.axis('off')\n",
        "\n",
        "        # Image Visualization\n",
        "        ax2 = plt.subplot(gs[1])\n",
        "        if hasattr(data, 'frame_path') and os.path.exists(data.frame_path):\n",
        "            img = Image.open(data.frame_path)\n",
        "            ax2.imshow(img)\n",
        "            ax2.set_title(\"Original Frame\")\n",
        "            ax2.axis('off')\n",
        "        else:\n",
        "            ax2.text(0.5, 0.5, \"Image not found\", ha='center', va='center')\n",
        "            ax2.axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        print(\"\\nTop 5 Important Body Parts:\")\n",
        "        top_importances = torch.topk(importance, k=5)\n",
        "        for idx, score in zip(top_importances.indices, top_importances.values):\n",
        "            part_name = data.body_part_labels.get(idx.item(), f\"Node {idx.item()}\")\n",
        "            print(f\"{part_name}: {score.item():.4f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Visualization error: {str(e)}\")\n",
        "\n",
        "# 4. Initialize dataset\n",
        "train_dataset = PoseGraphDataset(train_graph_dir, train_frame_dir, mode='train')\n",
        "\n",
        "# 5. Load or create model\n",
        "model = ExplainableGCN().to(device)\n",
        "\n",
        "# Try to load pretrained weights\n",
        "model_path = \"best_gcn_model.pth\"\n",
        "if os.path.exists(model_path):\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    print(\"Loaded pretrained model weights\")\n",
        "else:\n",
        "    print(\"Initialized new model (no pretrained weights found)\")\n",
        "\n",
        "# 6. Generate visualizations\n",
        "sample_indices = [0, 5, 10]  # Different samples to visualize\n",
        "for idx in sample_indices:\n",
        "    if idx < len(train_dataset):  # Check if index is valid\n",
        "        sample_data = train_dataset[idx].to(device)\n",
        "        node_importances, pred_class = model.compute_node_importance(sample_data)\n",
        "        visualize_graph_with_image(sample_data, node_importances, pred_class)\n",
        "    else:\n",
        "        print(f\"Skipping index {idx} - exceeds dataset size\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZhTrhiYWbsjN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}